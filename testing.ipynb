{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5908559,"sourceType":"datasetVersion","datasetId":3392987},{"sourceId":5915874,"sourceType":"datasetVersion","datasetId":3397661},{"sourceId":5916189,"sourceType":"datasetVersion","datasetId":3397778},{"sourceId":5917831,"sourceType":"datasetVersion","datasetId":3398595}],"dockerImageVersionId":30702,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-21T06:13:14.172707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\n\n# Define preprocessing function\ndef preprocess(df):\n    drop_list = [\"ados_preTest_communication\", \"ados_preTest_interaction\", \"ados_preTest_module\", \"ados_preTest_play\",\n                 \"ados_preTest_protocol\", \"ados_preTest_socialCommunicationQuestionnaire\", \"ados_preTest_stereotype\",\n                 \"condition\", \"frame_rate\", \"participant_gender\", \"participant_id\", \"skeleton_elbow_left_confidence\",\n                 \"skeleton_elbow_right_confidence\", \"skeleton_hand_left_confidence\", \"skeleton_hand_right_confidence\",\n                 \"skeleton_head_confidence\", \"skeleton_sholder_center_confidence\", \"skeleton_sholder_left_confidence\",\n                 \"skeleton_sholder_right_confidence\", \"skeleton_wrist_left_confidence\", \"skeleton_wrist_right_confidence\",\n                 \"task_ability\", \"task_difficultyLevel\", \"task_end\", \"task_index\", \"task_start\", \"time\"]\n    print(df.columns)\n    df.drop(drop_list, axis=1, inplace=True)\n    df.dropna(axis=0, inplace=True)\n    df = df[::5].reset_index(drop=True)\n    return df\n\n# Define function to generate image from DataFrame\ndef getImage(df, image_size=30):\n    ans = []\n    for _, d in df.iterrows():\n        image = np.zeros((image_size, image_size, 1), dtype=np.uint8)\n        # Draw circles and lines for skeleton joints\n        # Your code for drawing circles and lines goes here\n        ans.append(image)\n    return ans\n\n# Define function to open JSON files\ndef open_json(path):\n    with open(path) as f:\n        return json.load(f)\n\n# Define function to load data\ndef load_data(directory):\n    videos = []\n    y = []\n    per_user = 10\n    for user_dir in os.listdir(directory):\n        user_count = 0\n        for _, _, filenames in os.walk(os.path.join(directory, user_dir)):\n            for filename in filenames:\n                if user_count == per_user:\n                    break\n                data = open_json(os.path.join(directory, user_dir, filename))\n                df = pd.DataFrame(data)\n                df = preprocess(df)\n                if df.shape[0] == 0:\n                    continue\n                y.append(df[\"ados_preTest_total\"].iloc[0])\n                videos.append(df.drop([\"ados_preTest_total\"], axis=1))\n                user_count += 1\n    return videos, y\n\n# Load data\ndataset_directory = \"/kaggle/input/dream-dataset-part1/Part 1 Users\"\nvideos, y = load_data(dataset_directory)\n\n# Process video data\nimage_size = 30\nX = np.array([getImage(video, image_size) for video in videos])\n\n# Split data into train and test sets\nX_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define the neural network model\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        # Convolutional block\n        self.conv2Dblock = nn.Sequential(\n            # 1st convolutional block\n            nn.Conv2d(in_channels=1,\n                      out_channels=16,\n                      kernel_size=3,\n                      stride=1,\n                      padding=1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Dropout(p=0.2),\n            # 2nd convolutional block\n            nn.Conv2d(in_channels=16,\n                      out_channels=32,\n                      kernel_size=3,\n                      stride=1,\n                      padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=4, stride=4),\n            nn.Dropout(p=0.2),\n            # 3rd convolutional block\n            nn.Conv2d(in_channels=32,\n                      out_channels=64,\n                      kernel_size=3,\n                      stride=1,\n                      padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=4, stride=4),\n            nn.Dropout(p=0.2)\n        )\n        # LSTM block\n        hidden_size = 128\n        self.lstm = nn.LSTM(input_size=192, hidden_size=hidden_size, bidirectional=True, batch_first=True)\n        self.dropout_lstm = nn.Dropout(p=0.3)\n        self.attention_linear = nn.Linear(2 * hidden_size, 1)  # 2 * hidden_size for the 2 outputs of bidirectional LSTM\n        # Linear softmax layer\n        self.out_linear = nn.Linear(2 * hidden_size, 1)\n\n    def forward(self, x):\n        batch_size, time_steps, height, width = x.size()\n        x = x.view(batch_size * time_steps, 1, height, width)\n        conv_embedding = self.conv2Dblock(x)\n        conv_embedding = conv_embedding.view(batch_size, time_steps, -1, conv_embedding.size(2), conv_embedding.size(3))\n        conv_embedding = torch.flatten(conv_embedding, start_dim=2)  # Do not flatten batch dimension and time\n        lstm_embedding, (h, c) = self.lstm(conv_embedding)\n        lstm_embedding = self.dropout_lstm(lstm_embedding)\n        # LSTM embedding (batch, time, hidden_size*2)\n        batch_size, T, _ = lstm_embedding.shape\n        attention_weights = [None] * T\n        for t in range(T):\n            embedding = lstm_embedding[:, t, :]\n            attention_weights[t] = self.attention_linear(embedding)\n        attention_weights_norm = nn.functional.softmax(torch.stack(attention_weights, -1), dim=-1)\n        attention = torch.bmm(attention_weights_norm, lstm_embedding)  # (Bx1xT)*(B,T,hidden_size*2)=(B,1,2*hidden_size)\n        attention = torch.squeeze(attention, 1)\n        prediction = self.out_linear(attention)\n\n        return prediction\n\n# Initialize the model, optimizer, and loss function\nmodel = MyModel()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nloss_fn = nn.MSELoss()\n\n# Convert data to PyTorch tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\nY_train_tensor = torch.tensor(Y_train, dtype=torch.float32).to(device)\n\n# Train the model\nepochs = 1000\nmodel.train()\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    outputs = model(X_train_tensor)\n    loss = loss_fn(outputs, Y_train_tensor)\n    loss.backward()\n    optimizer.step()\n    if epoch % 100 == 0:\n        print(f\"Epoch {epoch}: Loss {loss.item()}\")\n\n# Evaluate the model on test data\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\nY_test_tensor = torch.tensor(Y_test, dtype=torch.float32).to(device)\nmodel.eval()\nwith torch.no_grad():\n    test_outputs = model(X_test_tensor)\n    test_loss = loss_fn(test_outputs, Y_test_tensor)\n    print(f\"Test Loss: {test_loss.item()}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}